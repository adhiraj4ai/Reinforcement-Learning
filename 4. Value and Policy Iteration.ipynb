{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Value Iteration\n",
    "Value Iteration is a dynamic programming technique used in reinforcement learning to find value function by iteratively solving the bellman equation. It is a common method in reinforcement learning (RL) for determining the best course of action or resolution for a Markov Decision Process (MDP) is the value iteration algorithm. \n",
    "\n",
    "The value iteration algorithm works by iteratively computing and updating the value function, which represents the expected cumulative reward an agent can receive by following a particular policy from a given state. The goal is to find the optimal value function, which corresponds to the optimal policy that maximizes the expected total reward.\n",
    "\n",
    "In value iteration, we first compute the optimal value function and then use it to extract the optimal policy. The optimal policy is the one through which agent takes best action with best reward possible in every state to transit from initial to final state.\n",
    "\n",
    "The working mechanism of Value Iteration algorithm is as follow:\n",
    "\n",
    "1. **Initialize the value function**: Start with an initial estimate of the value function, often by setting all state values to zero or a small random value.\n",
    "2. **Iterate**: Repeat the following steps until the value function converges (i.e., the maximum change in the value function between iterations is below a predefined threshold):\n",
    "\\begin{equation}\n",
    "V^*(s) = max_a\\sum_{s'}{P(s'|s,a)[R(s,a,s') + \\gamma V^*(s')]}\n",
    "\\end{equation}\n",
    "    \n",
    "3. **Extract the optimal policy**: After convergence, the optimal policy can be derived by choosing the action from each state that maximizes the right-hand side of the Bellman equation.\n",
    "\n",
    "Value iteration is a widely used algorithm because of its ease in the implementation and comprehension, and its ability to identify the best course of action without explicitly examining every conceivable state-action sequence. However, because iterating over every state in each iteration can be costly computationally for huge state spaces.A common method in reinforcement learning (RL) for determining the best course of action or resolution for a Markov Decision Process (MDP) is the value iteration algorithm.\n",
    "\n",
    "As long as the MDP satisfies certain characteristics (e.g., the Markov property and the availability of adequate policies) and the discount factor `Î³` is smaller than 1, the method is guaranteed to converge to the optimal value function and policy for any finite MDP. The optimal value function obtained from value iteration algorithm represents the maximum expected cumulative reward that can be obtained from each state by following the optimal policy.\n",
    "\n",
    "Using the bellman equation, we can obtain the optimal value function as:\n",
    "\n",
    "\\begin{equation}\n",
    "V^*(s) = max_a\\sum_{s'}{P(s'|s,a)[R(s,a,s') + \\gamma V^*(s')]}\n",
    "\\end{equation}\n",
    "\n",
    "Or, the Q function as:\n",
    "\n",
    "\\begin{equation}\n",
    "Q^*(s, a) = \\sum_{s'}{P(s'|s,a)[R(s,a,s') + \\gamma Q^*(s', a')]}\n",
    "\\end{equation}\n",
    "\n",
    "which means, \n",
    "\\begin{equation}\n",
    "V^*(s) = max _a Q^*(s, a)\n",
    "\\end{equation}\n",
    "\n",
    "i.e. we can compute the optimal value function by just taking the maximum over the optimal $Q$ function. Thus, in order to compute the optimal value of any state over state space $S$, we can take the maximum of $Q$ values obtained form all of the state-action pairs."
   ],
   "id": "ae7d73247c07459a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![ValueIteration](https://github.com/adhiraj4ai/Reinforcement-Learning/blob/theory/Images/Value%20Iteration.png)",
   "id": "3b881db0569e6021"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
