{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action Space\n",
    "Consider a grid world as shown below:\n",
    "\n",
    "// Grid World Image\n",
    "\n",
    "The agent is initially located at A (marked with *) and the goal of the agent is to reach state H (marked with #). The agent should reach the goal state from initial state without visiting the shaded state. In each of the states, the agent can perform any of the four states as *left, right, up and down*, which is known as action space. **Thus, the set of all possible actions in the state space of environment is called action space.**\n",
    "\n",
    "Action space can either be discrete or continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Action Space\n",
    "An action space which contains finite number of actions in state space of environment is known as **Discrete Action Space**. For example, in the above grid world environment, we have four distinct actions that agent can take. THus it is discrete action space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Action Space\n",
    "When there are infinite number of values for actions possible in any state space of environment then it is known as **Continuous Action Space**. For example, autonomous car in a road has severate actions such as rotating the wheel, speed of wheel which are all defined by continuous value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy\n",
    "A **policy** defines the behaviour of agent i.e. how and what actions agent should take is determined by policy. The policy guides the agent on what action to take in each state of the environment. For example, in our grid world environment, policy determines whether to take left, right, up or down based on some experience or learning. The policy may guide agent to move from state A to B with action right or A to D with action down.\n",
    "\n",
    "A good policy guides agent successfuly to reach their goal with good reward. And, if the agent achieves the best possible reward over reaching its goal, then it is known as **Optimal Policy**. That is, optimal policy guides the agent to take right action in each state so that the agent reaches the goal receiving the best reward.\n",
    "\n",
    "A policy can be of following two types:\n",
    "1. Deterministic Policy\n",
    "2. Stochastic Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Deterministic Policy\n",
    "If a policy guides an agent to take one specific action in a state then it is called **Deterministic Policy**. The deterministic policy, thus, maps the state to one particular action for an agent to take. It is denoted by $\\mu$ and expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "a_t = \\mu(s_t)\n",
    "\\end{equation}\n",
    "\n",
    "In case of our grid world example, the policy is deterministic and it guides an agent to take `down` action in state A.\n",
    "\n",
    "A --> Down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stochastic Policy\n",
    "Unlike a deterministic policy, a stochastic policy does not map a state directly to one specific action, instead it maps the state to a probability distribution over an action space. Given a state for an agent, the stochastic policy will return a probability distribution over all actions possible in that particular state due to which agents ends up taking different action each time agent visits the state. It is denoted by $\\pi$ and is given as:\n",
    "\n",
    "\\begin{equation}\n",
    "a_t ~ \\pi(a_t|s_t)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Categorical Stochastic Policy**: \n",
    "A stochastic policy is called a categorical stochastic policy when the action space is discrete. \n",
    "For example,\n",
    "\n",
    "A -> [0.10, 0.70, 0.15, 0.05]\n",
    "\n",
    "       up, down, right, left\n",
    "\n",
    "\n",
    "### **Gaussian Stochastic Policy**: \n",
    "A stochastic policy is called a gaussian stochastic policy when our action space is continious i.e. we use gaussian probability distribution over the action space to select actions when the action space is continious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
